import{_ as m,c as s,a as t,f as r,d as i,r as c,o as d,h as f,n as p,j as g,e as l,t as a}from"./index-CuvdokFr.js";const b="/assets/TottiLabs-BdnD-wsf.png",w="/assets/OrnithologyLab-CI46TeMW.png",v="/assets/BirdVox-Dj2ljNEr.png",y="/assets/weill-CjpDKeN5.png",k={data(){return{events:[{status:"Medical Education Advising",date:"Present",location:"New York, NY",image:y,description:"Through a collaboration of Cornell Tech and Weill Cornell, this research project is targeted at making medical education advising easier for both students and advisors. The goal is to create a chatbot which students can interact with in place of an advisor. With data from past Weill students and specific advice from Cornell's advisors, the chatbot should be able to give specialized and personalized advice on medical career questions and how to rank residencies during their fourth year of medical school.",contribution:"Working with Dr. Kaushal Shah, I am exploring options for the chatbot, including finetuning a LLM and using RAG."},{status:"One Button Tracker",date:"May 2023 - Jul 2023",location:"Lyngby, DK",image:b,description:"One Button Tracker is a portable device used to help monitor the effects of PTSD developed by TOTTI Labs, a lab based in Denmark. Patients carry the tracker with them and press the button when they experience stress.",contribution:"Working with Dr. Jakob Eg Larsen, I contributed to the One Button Tracker project by building upon an extensive set of pre-existing code to create multiple graphical interfaces that may be used for physicians to display the results of the One Button Tracker to their patients. I adapted my skills in JavaScript to work in Observable Notebooks and produced four unique interfaces, including heat maps, histograms, and scatter plots with varying ranges."},{status:"BirdCast",date:"Jun 2022 - Dec 2022",location:"Ithaca, NY",image:w,description:"The BirdCast project uses machine learning to document and classify birds and uses information gained to learn more about bird migration. Audio files of bird calls are collected, annotated, and used to train a model that predicts the taxonomy of the bird.",contribution:"I worked with Dr. Benjamin van Doren and Dr. Andrew Farnsworth to analyze the extensive set of predictions from the machine learning model. I wrote functions to determine the accuracy of the model and analyzed ways to optimize the model’s predictions’ precision and recall on the family, order, and species levels."},{status:"NSF BirdVox",date:"Feb 2021 - May 2021",location:"Remote",image:v,description:"BirdVox focuses on bioacoustic research on species classification in natural environments. The research includes creating a large dataset and classifying flight calls.",contribution:"Under the supervision of Dr. Andrew Farnsworth, I annotated audio files for the machine learning team to use for their model to predict birds based on their calls. I worked in Raven Pro and manually labeled thousands of bird calls."},{status:"Independent Research",date:"Oct 2018 - Feb 2020",location:"Eastchester, NY",description:"Research focused on the effects of artificial lignt at night on nocturnal organisms, specifically moths.",contribution:"I developed and completed an experiment to analyze the effects of different wavelengths of light on moth fitness. Moths were placed under different colored lights and observed for several months, and fitness was measured by mass. Results indicated that red light is better to reduce light pollution."}],isMobile:window.innerWidth<1e3}},mounted(){window.addEventListener("resize",this.handleResize)},beforeUnmount(){window.removeEventListener("resize",this.handleResize)},methods:{handleResize(){this.isMobile=window.innerWidth<768}}},_={class:"about"},T={class:"vertical"},x={class:"card timeline-wrapper"},z=["src","alt"];function B(C,n,D,I,o,N){const h=c("Card"),u=c("Timeline");return d(),s("div",_,[t("div",T,[n[0]||(n[0]=t("div",{class:"para"},[t("h2",null,"Research"),t("p",null,"My research interests have transitioned over time and currently, I am looking to continue doing research on how to draw meaningful conclusions from wearable devices and using machine learning for impactful purposes. Here is a brief timeline of the research projects I have contributed to:")],-1)),t("div",x,[r(u,{value:o.events,align:o.isMobile?"left":"alternate",class:"customized-timeline"},{opposite:i(e=>[e.item.image?(d(),s("img",{key:0,src:`${e.item.image}`,alt:e.item.name,width:"200",class:"shadow-sm"},null,8,z)):f("",!0)]),marker:i(e=>[t("span",{class:"flex w-8 h-8 items-center justify-center text-white rounded-full z-10 shadow-sm",style:p({backgroundColor:e.item.color})},[t("i",{class:g(e.item.icon)},null,2)],4)]),content:i(e=>[r(h,{class:"mt-4"},{title:i(()=>[l(a(e.item.status),1)]),subtitle:i(()=>[l(a(e.item.date)+" ",1),t("p",null,a(e.item.location),1)]),content:i(()=>[t("p",null,a(e.item.description),1),t("p",null,a(e.item.contribution),1)]),_:2},1024)]),_:1},8,["value","align"])])])])}const j=m(k,[["render",B]]);export{j as default};
